{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n",
    "The Iris dataset is comprised of 150 instances of Iris flowers from three different species  (classes),  where  each  class  refers  to  a  type  of Iris  plant.  There  are  4 attributes of given flowers: sepal length, sepal width, petal length and petal width, \n",
    "all in the same unit of centimeters.\n",
    "\n",
    "The predicted attribute is the species, which is one of Setosa, Versicolor and Virginica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3  4\n",
       "0  5.1  3.5  1.4  0.2  0\n",
       "1  4.9  3.0  1.4  0.2  0\n",
       "2  4.7  3.2  1.3  0.2  0\n",
       "3  4.6  3.1  1.5  0.2  0\n",
       "4  5.0  3.6  1.4  0.2  0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IRIS-2.csv\",header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Shuffle and split the IRIS-dataset into train/test datasets (with 66%/34% split).\n",
    "* X_train: contains  all  features  from the training set\n",
    "* y_train: contains the class label (flower species) of the training set\n",
    "* X_test: contains all features of the testset\n",
    "* y_test: contains the class label of the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path,header=None)\n",
    "    df = df.sample(frac=1) #Shuffles the dataset\n",
    "    X_train = df.iloc[:100, :4] #66%\n",
    "    X_test = df.iloc[100:150,:4] #34%\n",
    "    y_train = df.iloc[:100, 4]\n",
    "    y_test = df.iloc[100:150,4]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance\n",
    "$$Euclidean\\, Distance \\, (x,y) = \\sqrt{\\sum_{i=1}^n (x_{i}-y_{i})^2}$$\n",
    "\n",
    "Calculate the euclidean distance between a test object (x) and all instances in the training dataset.\n",
    "np.linalg.norm with axis=1 performs vector norm calculations between the testobject and trainingset. The function then returns the matrix norm that contains every euclidean distance betweem them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(testobject,trainingset):\n",
    "    return np.linalg.norm(testobject - trainingset, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find neighbors\n",
    "Locate the k most similar data instances to the test object, based on the computed euclidean distance vector. \n",
    "The distance vector is sorted in ascendic order, and then sliced into the k-first elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(k,array):\n",
    "    return np.argsort(array)[:k] #Returns the indices that would sort an array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the class\n",
    "Assign the most common label of the k nearest neighbors to the class label of the test example. K indexes is used to look up the labels in ytrain, count them by np.bincount, before returning the most frequent one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(indexes, array):\n",
    "    #count = np.bincount([array[x] for x in indexes]), then argmax(count)\n",
    "    return np.argmax(np.bincount([array[x] for x in indexes])) #as a one-liner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN\n",
    "Produce predictions for all instances in the test dataset. The dataframes is first converted into numpy arrays in order to performe efficient calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a list of predictions\n",
    "def k_nearest_neighbors(xtrain,xtest,ytrain,ytest,k):\n",
    "    xtrain, xtest, ytrain, ytest = np.array(xtrain), np.array(xtest), np.array(ytrain), np.array(ytest)\n",
    "    predictions = []\n",
    "    for element in xtest:\n",
    "        euclidean_distances = euclidean_distance(element,xtrain) #list of euclidean distances from the element\n",
    "        neighbors = find_neighbors(k,euclidean_distances) #k nearest elements\n",
    "        prediction = majority_class(neighbors,ytrain) #class of the most common label\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_k_nearest_neighbors(xtrain,xtest,ytrain,k):\n",
    "    xtrain, xtest, ytrain = np.array(xtrain), np.array(xtest), np.array(ytrain)\n",
    "    #perform every needed function in one comprehension\n",
    "    return [majority_class(x,ytrain) for x in [find_neighbors(k,x) for x in [euclidean_distance(x,xtrain) for x in xtest]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Classification accuracy is a ratio of the total correct predictions out of all predictions made. The function is simply counting each correct prediction by comparing it to the y_test (true labels). Accuracy is computed by #correct/length-testset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(pred, true):\n",
    "    correct = 0\n",
    "    for i, prediction in enumerate(pred):\n",
    "        if prediction == true[i]:\n",
    "            correct += 1\n",
    "    return correct/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method\n",
    "Call each seperate function with an appropriate order to produce the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    xtrain, xtest, ytrain, ytest = load_data(\"IRIS-2.csv\") #Load the IRIS dataset\n",
    "    #predictions = k_nearest_neighbors(xtrain,xtest,ytrain,ytest,5) #List of predictions with k=5\n",
    "    predictions = opt_k_nearest_neighbors(xtrain,xtest,ytrain,5)\n",
    "    accuracy = model_accuracy(predictions,np.array(ytest))\n",
    "    #print(\"Model accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "### Main method\n",
    "The main method loads, predict and computes the accuracy of the KNN algorithm. I used the built in magic command %timeit to profile my code. The %timeit command measures more accurate results than the regular %time as it repeats execution of a single statement. My results from the main method:\n",
    "* 5.27 ms ± 301 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) (with print of accuracy)\n",
    "* 4.85 ms ± 179 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) (without print of accuray)\n",
    "* 4.08 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) (with the one-liner method opt_k_nearest_neighbors)\n",
    "\n",
    "This shows how efficient numpy calculations are. Removing the print statement also reduced the run time. My alternative KNN method opt_k_nearest_neighbors() runs faster than the regular one. The method is however not as clear and understandable as the other one.\n",
    "\n",
    "To go more in depth of where the algorithm spend most of it execution time, I look at different parts by itself. Pandas is used to load the dataset into dataframes in load_data(). This part is pretty straightforward and there is not much more to do in terms of efficiency. Looking at the execution time of the load_data() I get:\n",
    "* 3.11 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "\n",
    "The entire method then spend most of its time loading the data. This means all the calculations after the data is loaded, runs in under 1.0 ms. Checking it out with %timeit, I get:\n",
    "* 1.07 ms ± 7.16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) (For calculating predictions)\n",
    "* 34 µs ± 773 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each) (For calculating the accuracy)\n",
    "\n",
    "The KNN calculations is completed in 1.07ms. This is the measurements of the key parts within the function (one xtest element):\n",
    "* 8.77 µs ± 327 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) (For calculation the euclidean distances)\n",
    "* 2.64 µs ± 52 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) (For calculating the nearest neighbors)\n",
    "* 4.7 µs ± 48.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) (For finding majority class)\n",
    "* 4.62 µs ± 94.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) (For append prediction to list (regular knn methos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.09 ms ± 30.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
